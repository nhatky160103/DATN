import torch
import torch.nn as nn
from iresnet_lightweight import iresnet_lightweight

def analyze_model_parameters(model):
    """PhÃ¢n tÃ­ch chi tiáº¿t sá»‘ tham sá»‘ cá»§a tá»«ng thÃ nh pháº§n trong model"""
    
    print("ğŸ” PHÃ‚N TÃCH THAM Sá» MODEL")
    print("=" * 60)
    
    total_params = 0
    component_params = {}
    
    # PhÃ¢n tÃ­ch tá»«ng module
    for name, module in model.named_modules():
        if len(list(module.children())) == 0:  # Chá»‰ láº¥y leaf modules
            params = sum(p.numel() for p in module.parameters())
            if params > 0:
                component_params[name] = params
                total_params += params
    
    # Sáº¯p xáº¿p theo sá»‘ tham sá»‘ giáº£m dáº§n
    sorted_components = sorted(component_params.items(), key=lambda x: x[1], reverse=True)
    
    print(f"ğŸ“Š Tá»”NG Sá» THAM Sá»: {total_params:,}")
    print()
    
    print("ğŸ† TOP 10 THÃ€NH PHáº¦N CHIáº¾M NHIá»€U THAM Sá» NHáº¤T:")
    print("-" * 60)
    
    for i, (name, params) in enumerate(sorted_components[:10], 1):
        percentage = (params / total_params) * 100
        print(f"{i:2d}. {name:<40} {params:>10,} ({percentage:>5.1f}%)")
    
    print()
    
    # PhÃ¢n tÃ­ch theo loáº¡i layer
    conv_params = 0
    bn_params = 0
    fc_params = 0
    other_params = 0
    
    for name, params in component_params.items():
        if 'conv' in name.lower():
            conv_params += params
        elif 'bn' in name.lower() or 'batch' in name.lower():
            bn_params += params
        elif 'fc' in name.lower() or 'linear' in name.lower():
            fc_params += params
        else:
            other_params += params
    
    print("ğŸ“ˆ PHÃ‚N TÃCH THEO LOáº I LAYER:")
    print("-" * 40)
    print(f"Convolutional layers: {conv_params:>10,} ({(conv_params/total_params)*100:>5.1f}%)")
    print(f"BatchNorm layers:     {bn_params:>10,} ({(bn_params/total_params)*100:>5.1f}%)")
    print(f"Fully Connected:      {fc_params:>10,} ({(fc_params/total_params)*100:>5.1f}%)")
    print(f"Others:               {other_params:>10,} ({(other_params/total_params)*100:>5.1f}%)")
    print()
    
    # PhÃ¢n tÃ­ch theo layer depth
    layer_params = {}
    for name, params in component_params.items():
        if 'layer' in name:
            layer_num = name.split('.')[0]  # layer1, layer2, etc.
            if layer_num not in layer_params:
                layer_params[layer_num] = 0
            layer_params[layer_num] += params
    
    print("ğŸ—ï¸  PHÃ‚N TÃCH THEO LAYER DEPTH:")
    print("-" * 40)
    for layer_name in sorted(layer_params.keys()):
        params = layer_params[layer_name]
        percentage = (params / total_params) * 100
        print(f"{layer_name:<10} {params:>10,} ({percentage:>5.1f}%)")
    print()
    
    # TÃ¬m thÃ nh pháº§n chiáº¿m nhiá»u nháº¥t
    max_component = max(component_params.items(), key=lambda x: x[1])
    print(f"ğŸ¯ THÃ€NH PHáº¦N CHIáº¾M NHIá»€U NHáº¤T:")
    print(f"   {max_component[0]}")
    print(f"   {max_component[1]:,} parameters ({(max_component[1]/total_params)*100:.1f}%)")
    print()
    
    # Gá»£i Ã½ tá»‘i Æ°u
    print("ğŸ’¡ Gá»¢I Ã Tá»I Æ¯U:")
    if fc_params > conv_params * 0.5:
        print("   âš ï¸  FC layer chiáº¿m quÃ¡ nhiá»u tham sá»‘!")
        print("   ğŸ’¡ Giáº£m output features tá»« 512 xuá»‘ng 256 hoáº·c 128")
    
    if max_component[1] > total_params * 0.3:
        print(f"   âš ï¸  {max_component[0]} chiáº¿m {(max_component[1]/total_params)*100:.1f}% tham sá»‘!")
        print("   ğŸ’¡ CÃ¢n nháº¯c giáº£m kÃ­ch thÆ°á»›c layer nÃ y")
    
    # TÃ­nh toÃ¡n model size
    model_size_mb = total_params * 4 / 1024 / 1024  # 4 bytes per float32
    print(f"ğŸ“¦ MODEL SIZE: {model_size_mb:.2f} MB (float32)")
    print(f"ğŸ¯ TARGET: â‰¤ 5M params = â‰¤ 19.07 MB")
    print(f"âœ… Status: {'Äáº¡t' if total_params <= 5000000 else 'ChÆ°a Ä‘áº¡t'} má»¥c tiÃªu")

def detailed_fc_analysis(model):
    """PhÃ¢n tÃ­ch chi tiáº¿t FC layer"""
    print("\nğŸ” PHÃ‚N TÃCH CHI TIáº¾T FC LAYER:")
    print("-" * 40)
    
    for name, module in model.named_modules():
        if isinstance(module, nn.Linear):
            input_features = module.in_features
            output_features = module.out_features
            params = sum(p.numel() for p in module.parameters())
            
            print(f"Layer: {name}")
            print(f"  Input features:  {input_features:,}")
            print(f"  Output features: {output_features:,}")
            print(f"  Parameters:      {params:,}")
            print(f"  Size:            {params * 4 / 1024 / 1024:.2f} MB")
            print()

def main():
    # Táº¡o model
    model = iresnet_lightweight()
    model.eval()
    
    # PhÃ¢n tÃ­ch
    analyze_model_parameters(model)
    detailed_fc_analysis(model)
    
    # Thá»‘ng kÃª tá»•ng quan
    print("ğŸ“Š THá»NG KÃŠ Tá»”NG QUAN:")
    print("-" * 40)
    
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"Total parameters:     {total_params:,}")
    print(f"Trainable parameters: {trainable_params:,}")
    print(f"Non-trainable:       {total_params - trainable_params:,}")
    print(f"Model size (float32): {total_params * 4 / 1024 / 1024:.2f} MB")
    print(f"Model size (float16): {total_params * 2 / 1024 / 1024:.2f} MB")

if __name__ == "__main__":
    main() 